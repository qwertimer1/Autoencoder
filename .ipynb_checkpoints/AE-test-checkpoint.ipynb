{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test 1 - New data format with seq_len incorporated into dataset code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# Import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "##Needs to be imported before sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader #as DataLoaderBase\n",
    "from torch import nn, optim, sigmoid\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import modules\n",
    "from torch.nn.modules import loss\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#from torchaudio import transforms\n",
    "#from torchaudio import Datasets\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from glob import glob\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "#from torchviz import make_dot, make_dot_from_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check device type\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_creator(T = 20, L = 10000, N = 1000):\n",
    "    \"\"\"\n",
    "    Simple sine wave creator. Used to build a large dataset of sine waves.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "\n",
    "\n",
    "\n",
    "    x = np.empty((N, L), 'int64')\n",
    "    x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "    data = np.sin(x / 1.0 / T).astype('float64')\n",
    "    data = sklearn.preprocessing.normalize(data)\n",
    "\n",
    "    torch.save(data, open('traindata.pt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Code adapted from ----\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, isCuda):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.isCuda = isCuda\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #initialize weights\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "\n",
    "    def forward(self, input):\n",
    "        tt = torch.cuda if self.isCuda else torch\n",
    "        h0 = Variable(tt.FloatTensor(self.num_layers, input.size(0), self.hidden_size))\n",
    "        c0 = Variable(tt.FloatTensor(self.num_layers, input.size(0), self.hidden_size))\n",
    "        encoded_input, hidden = self.lstm(input, (h0, c0))\n",
    "        encoded_input = self.relu(encoded_input)\n",
    "        return encoded_input\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, isCuda):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.isCuda = isCuda\n",
    "        self.lstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True)\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        #initialize weights\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        \n",
    "    def forward(self, encoded_input):\n",
    "        tt = torch.cuda if self.isCuda else torch\n",
    "        h0 = Variable(tt.FloatTensor(self.num_layers, encoded_input.size(0), self.output_size))\n",
    "        c0 = Variable(tt.FloatTensor(self.num_layers, encoded_input.size(0), self.output_size))\n",
    "        decoded_output, hidden = self.lstm(encoded_input, (h0, c0))\n",
    "        #decoded_output = self.sigmoid(decoded_output)\n",
    "        return decoded_output\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, isCuda):\n",
    "        super(LSTMAE, self).__init__()\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, num_layers, isCuda)\n",
    "        self.decoder = DecoderRNN(hidden_size, input_size, num_layers, isCuda)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        encoded_input = self.encoder(input)\n",
    "        decoded_output = self.decoder(encoded_input)\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sineDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, seq_len, overlap):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        self.data = torch.load('traindata.pt')\n",
    "        self.label = []\n",
    "        self.seq_len = seq_len\n",
    "        self.overlap = overlap\n",
    "        vals = len(self.data)\n",
    "        for val in range(vals):\n",
    "            self.label.append(val)\n",
    "        if torch.cuda.is_available():\n",
    "            self.data, self.label = map(torch.cuda.FloatTensor, (self.data, self.label))\n",
    "        else:\n",
    "            self.data, self.label = map(torch.FloatTensor, (self.data, self.label))\n",
    "\n",
    "        self.data = self.window_mask()\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "        self.data.permute(2,1,0 )\n",
    "        print(\"shape = \", self.data.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def window_mask(self):\n",
    "        datavals = []\n",
    "        results = []\n",
    "        self.data= torch.tensor(self.data)\n",
    "        start_val = 0\n",
    "        occurences = int(len(self.data)/(self.seq_len*self.overlap))\n",
    "        \n",
    "        for rows in range(len(self.data)):\n",
    "\n",
    "            start_val = 0\n",
    "            for i in range(occurences-1):\n",
    "                \n",
    "                    value = self.data[rows,start_val:(start_val+self.seq_len)]\n",
    "                    \n",
    "                    start_val += int(self.seq_len*(1 - self.overlap))\n",
    "                    datavals.append(value.unsqueeze(0))\n",
    "\n",
    "            var = torch.cat(datavals)        \n",
    "            results.append(var.unsqueeze(0))\n",
    "            \n",
    "            datavals = []\n",
    "        result = torch.cat(results)\n",
    "        result = result.permute(2,1,0)\n",
    "        print(result.shape)\n",
    "        print(result)\n",
    "        return result\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_dataset, test_dataset, batch_size):\n",
    "    return (DataLoader(train_dataset, batch_size = batch_size),\n",
    "    DataLoader(test_dataset, batch_size = batch_size * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'seabedmodel',\n",
      " 'cuda': True,\n",
      " 'data_loader': {'batch_size': 32,\n",
      "                 'data_dir': 'datasets/',\n",
      "                 'shuffle': True,\n",
      "                 'type': 'ImageDataLoader'},\n",
      " 'gpu': 0,\n",
      " 'hyperparams': {'batch_size': 32,\n",
      "                 'hidden_dim': 400,\n",
      "                 'input_size': 1000,\n",
      "                 'latent': 5,\n",
      "                 'num_layers': 3,\n",
      "                 'overlap': 0.5,\n",
      "                 'seq_len': 200},\n",
      " 'loss': 'BCEWithLogitsLoss',\n",
      " 'loss_args': {'reduction': 'elementwise_mean'},\n",
      " 'metrics': ['my_metric', 'my_metric2'],\n",
      " 'model': {},\n",
      " 'name': 'Autoencoder',\n",
      " 'optimizer': {'lr': 1e-05, 'weight_decay': 0},\n",
      " 'optimizer_type': 'Adam',\n",
      " 'trainer': {'epochs': 1000,\n",
      "             'monitor': 'val_loss',\n",
      "             'monitor_mode': 'min',\n",
      "             'save_dir': 'saved/',\n",
      "             'save_freq': 1,\n",
      "             'verbosity': 2},\n",
      " 'validation': {'shuffle': True, 'test_split': 0.2, 'validation_split': 0.1},\n",
      " 'visualization': {'log_dir': 'saved/runs', 'tensorboardX': True}}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\n",
    "with open('config_file.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data)\n",
    "\n",
    "hyperparameters = data[\"hyperparams\"]\n",
    "optimiser = data[\"optimizer\"]\n",
    "trainer = data[\"trainer\"]\n",
    "loss_name = data[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 9, 1000])\n",
      "tensor([[[ 1.5308e-03, -5.5096e-03, -3.3845e-03,  ..., -1.2602e-02,\n",
      "           4.0674e-03, -1.3179e-02],\n",
      "         [ 1.3922e-02, -1.4059e-02,  1.2211e-02,  ..., -9.7256e-03,\n",
      "           1.4149e-02, -8.6514e-03],\n",
      "         [ 6.3675e-03, -2.4664e-03,  1.0312e-02,  ...,  7.0849e-03,\n",
      "           3.9594e-03,  8.2705e-03],\n",
      "         ...,\n",
      "         [ 1.4133e-02, -1.3725e-02,  1.3049e-02,  ..., -8.2814e-03,\n",
      "           1.4017e-02, -7.0951e-03],\n",
      "         [ 4.6392e-03, -6.0085e-04,  8.9397e-03,  ...,  8.6423e-03,\n",
      "           2.1268e-03,  9.7156e-03],\n",
      "         [-1.1501e-02,  1.3384e-02, -7.9771e-03,  ...,  1.3184e-02,\n",
      "          -1.2810e-02,  1.2607e-02]],\n",
      "\n",
      "        [[ 8.2591e-04, -4.8514e-03, -4.0667e-03,  ..., -1.2266e-02,\n",
      "           3.3851e-03, -1.2906e-02],\n",
      "         [ 1.3779e-02, -1.4121e-02,  1.1839e-02,  ..., -1.0227e-02,\n",
      "           1.4134e-02, -9.1996e-03],\n",
      "         [ 6.9910e-03, -3.1596e-03,  1.0783e-02,  ...,  6.4644e-03,\n",
      "           4.6333e-03,  7.6870e-03],\n",
      "         ...,\n",
      "         [ 1.4083e-02, -1.3880e-02,  1.2760e-02,  ..., -8.8439e-03,\n",
      "           1.4096e-02, -7.6975e-03],\n",
      "         [ 5.3015e-03, -1.3066e-03,  9.4765e-03,  ...,  8.0721e-03,\n",
      "           2.8232e-03,  9.1900e-03],\n",
      "         [-1.1075e-02,  1.3139e-02, -7.3833e-03,  ...,  1.3423e-02,\n",
      "          -1.2494e-02,  1.2911e-02]],\n",
      "\n",
      "        [[ 1.1895e-04, -4.1811e-03, -4.7388e-03,  ..., -1.1899e-02,\n",
      "           2.6942e-03, -1.2601e-02],\n",
      "         [ 1.3601e-02, -1.4147e-02,  1.1437e-02,  ..., -1.0702e-02,\n",
      "           1.4084e-02, -9.7247e-03],\n",
      "         [ 7.5971e-03, -3.8450e-03,  1.1227e-02,  ...,  5.8277e-03,\n",
      "           5.2957e-03,  7.0842e-03],\n",
      "         ...,\n",
      "         [ 1.3997e-02, -1.4000e-02,  1.2438e-02,  ..., -9.3844e-03,\n",
      "           1.4139e-02, -8.2807e-03],\n",
      "         [ 5.9505e-03, -2.0091e-03,  9.9896e-03,  ...,  7.4817e-03,\n",
      "           3.5126e-03,  8.6415e-03],\n",
      "         [-1.0621e-02,  1.2860e-02, -6.7710e-03,  ...,  1.3629e-02,\n",
      "          -1.2146e-02,  1.3183e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.4079e-03, -3.5681e-04,  8.7492e-03,  ...,  8.8341e-03,\n",
      "           1.8851e-03,  9.8915e-03],\n",
      "         [-1.1642e-02,  1.3462e-02, -8.1776e-03,  ...,  1.3094e-02,\n",
      "          -1.2912e-02,  1.2495e-02],\n",
      "         [-1.1013e-02,  7.9939e-03, -1.3389e-02,  ..., -1.4055e-03,\n",
      "          -9.2103e-03, -2.8030e-03],\n",
      "         ...,\n",
      "         [-1.2604e-02,  1.3920e-02, -9.6334e-03,  ...,  1.2272e-02,\n",
      "          -1.3564e-02,  1.1509e-02],\n",
      "         [-9.7400e-03,  6.3786e-03, -1.2666e-02,  ..., -3.2554e-03,\n",
      "          -7.7077e-03, -4.6126e-03],\n",
      "         [ 7.0779e-03, -1.0301e-02,  2.4475e-03,  ..., -1.4119e-02,\n",
      "           9.1912e-03, -1.4125e-02]],\n",
      "\n",
      "        [[ 5.0743e-03, -1.0633e-03,  9.2938e-03,  ...,  8.2712e-03,\n",
      "           2.5835e-03,  9.3741e-03],\n",
      "         [-1.1225e-02,  1.3227e-02, -7.5904e-03,  ...,  1.3345e-02,\n",
      "          -1.2607e-02,  1.2810e-02],\n",
      "         [-1.1443e-02,  8.5674e-03, -1.3600e-02,  ..., -7.0048e-04,\n",
      "          -9.7355e-03, -2.1068e-03],\n",
      "         ...,\n",
      "         [-1.2267e-02,  1.3775e-02, -9.1036e-03,  ...,  1.2608e-02,\n",
      "          -1.3346e-02,  1.1905e-02],\n",
      "         [-1.0241e-02,  7.0018e-03, -1.2965e-02,  ..., -2.5636e-03,\n",
      "          -8.2911e-03, -3.9388e-03],\n",
      "         [ 6.4567e-03, -9.8032e-03,  1.7481e-03,  ..., -1.4063e-02,\n",
      "           8.6421e-03, -1.4139e-02]],\n",
      "\n",
      "        [[ 5.7281e-03, -1.7671e-03,  9.8152e-03,  ...,  7.6877e-03,\n",
      "           3.2756e-03,  8.8333e-03],\n",
      "         [-1.0781e-02,  1.2960e-02, -6.9843e-03,  ...,  1.3562e-02,\n",
      "          -1.2270e-02,  1.3093e-02],\n",
      "         [-1.1844e-02,  9.1194e-03, -1.3778e-02,  ...,  6.2797e-06,\n",
      "          -1.0237e-02, -1.4054e-03],\n",
      "         ...,\n",
      "         [-1.1899e-02,  1.3597e-02, -8.5510e-03,  ...,  1.2912e-02,\n",
      "          -1.3094e-02,  1.2271e-02],\n",
      "         [-1.0716e-02,  7.6075e-03, -1.3232e-02,  ..., -1.8653e-03,\n",
      "          -8.8537e-03, -3.2551e-03],\n",
      "         [ 5.8194e-03, -9.2810e-03,  1.0443e-03,  ..., -1.3971e-02,\n",
      "           8.0714e-03, -1.4118e-02]]])\n",
      "shape =  torch.Size([200, 9, 1000])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000026180017748>\n"
     ]
    }
   ],
   "source": [
    " \n",
    "full_dataset = sineDataset( hyperparameters[\"seq_len\"], hyperparameters[\"overlap\"])\n",
    "full_dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "train_dl, test_dl = get_data(train_dataset, test_dataset, hyperparameters[\"batch_size\"])\n",
    "print(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    \n",
    "    #model = EncoderRNN(input_dim= input_dim, hidden_dim= hidden_dim).to(device)\n",
    "    model = LSTMAE(input_size = hyperparameters[\"input_size\"], hidden_size = hyperparameters[\"hidden_dim\"], num_layers = hyperparameters[\"num_layers\"], isCuda = False)\n",
    "\n",
    "    \n",
    "    return model, optim.Adam(model.parameters(), lr = optimiser[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(output, x): \n",
    "    #loss_fn = getattr(loss, loss_name)\n",
    "    #print(loss_fn)\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "    return loss_fn(output, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_function, xb, opt=None): \n",
    "    output = model(xb) \n",
    "    \n",
    "    loss = loss_function(output, xb)\n",
    "    print(loss)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.25)\n",
    "        opt.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, test_dl):\n",
    "    print(epochs)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for xb in train_dl:\n",
    "            \n",
    "            print(xb.shape)\n",
    "            #xb = xb.reshape(1,batch_size,input_size).to(device)  \n",
    "           \n",
    "            if torch.cuda.is_available():\n",
    "                xb = Variable(xb)\n",
    "            else:\n",
    "                xb = Variable(xb)\n",
    "            \n",
    "\n",
    "            loss_batch(model, loss_func, xb, opt)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                losses,nums = zip(*[loss_batch(model, loss_func, xb)\n",
    "                                    for xb in test_dl])\n",
    "            val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "        print(epoch, val_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model, opt = get_model()\n",
    "#x = torch.randn(1, 10000)\n",
    "#make_dot(model(x), params=dict(model.named_parameters()))\n",
    "\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 9, 1000])\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "tensor(nan)\n",
      "torch.Size([32, 9, 1000])\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-34d35c658efc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-5ba8ad6e454e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, loss_func, opt, train_dl, test_dl)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-59ae40148448>\u001b[0m in \u001b[0;36mloss_batch\u001b[1;34m(model, loss_function, xb, opt)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(trainer[\"epochs\"], model, loss_function, opt, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
